# -*- coding: utf-8 -*-
"""cluster_proverbs.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1g-IKCZACdke_Dbw2sOTrRMv8T4eXpt1d
"""

import os
import requests
import pandas as pd
import numpy as np
from sentence_transformers import SentenceTransformer
import umap
import hdbscan
import matplotlib.pyplot as plt
from collections import Counter
import re

# --------------------------
# إعدادات المسار والرابط
# --------------------------
DATA_PATH = "data/Yemeni_proverbs.json"
DATA_URL = "https://zenodo.org/record/XXXXXXX/files/Yemeni_proverbs.json?download=1"  # ← استبدله لاحقًا بالرابط الحقيقي

# --------------------------
# تنزيل الملف إذا لم يكن موجودًا
# --------------------------
if not os.path.exists(DATA_PATH):
    os.makedirs("data", exist_ok=True)
    print(f"⬇️ Downloading dataset from {DATA_URL} ...")
    response = requests.get(DATA_URL)
    if response.status_code == 200:
        with open(DATA_PATH, "wb") as f:
            f.write(response.content)
        print("✅ Dataset downloaded successfully.")
    else:
        raise Exception(f"❌ Failed to download dataset. Please check the URL or your internet connection.")

# --------------------------
# تحميل البيانات
# --------------------------
df = pd.read_json(DATA_PATH)
texts = df["proverb"].astype(str).tolist()

# --------------------------
# تحميل النموذج
# --------------------------
print("🔄 Loading Arabic-Triplet-Matryoshka-V2 model...")
model = SentenceTransformer("Omartificial-Intelligence-Space/Arabic-Triplet-Matryoshka-V2")

print("🔄 Generating embeddings...")
embeddings = model.encode(texts, batch_size=32, show_progress_bar=True)

# --------------------------
# تقليل الأبعاد (UMAP)
# --------------------------
umap_reducer = umap.UMAP(n_components=2, metric='cosine', random_state=42)
X_umap = umap_reducer.fit_transform(embeddings)

# --------------------------
# التجميع (HDBSCAN)
# --------------------------
clusterer = hdbscan.HDBSCAN(min_cluster_size=10, metric='euclidean', prediction_data=True)
labels = clusterer.fit_predict(X_umap)
df["cluster"] = labels

# --------------------------
# التصوير
# --------------------------
plt.figure(figsize=(10, 7))
scatter = plt.scatter(X_umap[:, 0], X_umap[:, 1], c=labels, cmap='tab20', s=20)
plt.title("Yemeni Proverbs Thematic Clustering\n(Arabic-Triplet-Matryoshka-V2 + UMAP + HDBSCAN)")
plt.xlabel("UMAP Component 1")
plt.ylabel("UMAP Component 2")
plt.colorbar(scatter, label="Cluster ID")
plt.grid(True)
plt.tight_layout()
plt.show()

# --------------------------
# الكلمات المفتاحية لكل مجموعة
# --------------------------
def tokenize(text):
    text = re.sub(r"[^\w\s]", "", text)
    return text.split()

print("\n📋 Top Keywords by Cluster:\n")
for cluster_id in sorted(df["cluster"].unique()):
    if cluster_id == -1:
        continue
    cluster_texts = df[df["cluster"] == cluster_id]["proverb"].tolist()
    tokens = []
    for text in cluster_texts:
        tokens.extend(tokenize(text))
    top_words = [word for word, freq in Counter(tokens).most_common(10)]
    print(f"🟩 Cluster {cluster_id} — Total Proverbs: {len(cluster_texts)}")
    print("Top Keywords:", top_words)
    print("-" * 50)